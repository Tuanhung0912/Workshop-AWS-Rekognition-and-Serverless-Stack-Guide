[
{
	"uri": "//localhost:1313/2-prerequiste/2.1-clonefrontend/",
	"title": "Clone and Setup Front-End",
	"tags": [],
	"description": "",
	"content": "Clone Project from Github Repository 1. Clone the Project using the Github Repository link\nFirst, please download and install the Javascript runtime environment to be able to run the project.\nReference installation link: node.js Next, please download and install a popular code editor such as Visual Studio Code or any equivalent code editor.\nReference installation link: Visual Studio Code Next, go to the project\u0026rsquo;s github link Click the green Code button and copy the Repository link as shown below: After accessing and copying the Repository link, Open Command Prompt in the folder where you want to store the Project as shown below Clone the Project into your desired folder with the following command: git clone https://github.com/Tuanhung0912/Workshop-AWS-Rekognition-and-Serverless-Stack-Frontend.git After cloning the Project from the Repository, you will see the result as shown below: 2. Open the Project and Setup\nAfter successfully cloning the Project from the Repository, Now, quickly open the Project using Command Prompt as shown below: After entering the command in Command Prompt to open the project, you will see the result as shown below: Next, install the necessary dependencies and libraries for the project to run in the node.js runtime environment. Open a Terminal in the Project and enter the following command: npm install Wait 1-2 minutes for the installation to complete. After installing the necessary libraries, a node_modules folder will appear in the Project as shown below: Next, update the libraries for Vite with the following command: npm update vite After running the above command to update the necessary libraries for Vite, you will see the result as shown below: 3. Run the Project\nNext, enter the following command to start the website: npm run dev After running the above command, the Terminal will display the following result: Visit http://localhost:5173/ to launch the website. Wait 1-2 minutes for the Project to build on the first run. After the build is complete, the website will be displayed as shown below: You have completed the first step to set up and launch\n"
},
{
	"uri": "//localhost:1313/3-lambdafunction/3.1-analyzefunction/",
	"title": "Configure Analyze Function",
	"tags": [],
	"description": "",
	"content": "Configure the Analyze Function to perform image analysis 1. Search for and access the Lambda service page\nIn the search bar, enter: Lambda The result will be displayed as shown below: On the main page of the Lambda service, create a new Function by clicking the Create a function button as shown below: Next, you will be taken to the configuration page for the Lambda Function as shown below: 2. Configure the Analyze Function on the Create a function page\nOn the creation page, to configure the function you are about to create, You need to enter information and select the most suitable configurations for the lab. Please follow these steps: In the first section, there are 3 options to create a template for the Lambda Function: Author from scratch, Use a blueprint, Container image\nSelect Author from scratch, this will create a simple code structure with a sample content that prints Hello World In the Basic information section:\nFunction name: enter a name for the function. For example: AnalyzeImage (or any name you prefer) Runtime: select Python 3.11 Architecture: select x86_64 In the Change default execution role section:\nExecution role: select Use an existing role, this allows you to choose a Role that was created earlier and is suitable for the Lambda Function Existing role: select LambdaAnalyzeRole, this is the Role created in the previous section After configuring, click the Create function button to create the Lambda function Result as shown below: Wait a few seconds for the system to create the Lambda function you have configured After creation, the system will return a successful creation notification for your Lambda function as shown below: Here is where you can write code in Python as configured earlier: 3. Configure the Analyze Function code in the Code Source section\nHere you will enter the code so that the image analysis function can work Enter the code with the following structure: import json import boto3 import base64 # Initialize Rekognition client to call the image recognition service rekognition = boto3.client(\u0026#39;rekognition\u0026#39;) def lambda_handler(event, context): try: # Check if the request body exists if \u0026#39;body\u0026#39; not in event or not event[\u0026#39;body\u0026#39;]: return { \u0026#34;statusCode\u0026#34;: 400, \u0026#34;body\u0026#34;: json.dumps({\u0026#34;error\u0026#34;: \u0026#34;Empty request body\u0026#34;}) } # Get the body from the incoming event (check if it\u0026#39;s base64) body_str = event[\u0026#39;body\u0026#39;] if event.get(\u0026#34;isBase64Encoded\u0026#34;): # If API Gateway is configured to send base64 body_str = base64.b64decode(event[\u0026#39;body\u0026#39;]).decode(\u0026#39;utf-8\u0026#39;) # Convert JSON string to Python dictionary body = json.loads(body_str) # Get the base64 image data from the \u0026#34;image\u0026#34; field image_base64 = body.get(\u0026#39;image\u0026#39;) # If there is no image, return an error if not image_base64: return { \u0026#34;statusCode\u0026#34;: 400, \u0026#34;body\u0026#34;: json.dumps({\u0026#34;error\u0026#34;: \u0026#34;Missing \u0026#39;image\u0026#39; in request body\u0026#34;}) } # Decode the image from base64 to bytes image_bytes = base64.b64decode(image_base64) # Call AWS Rekognition to detect labels in the image response = rekognition.detect_labels( Image={\u0026#39;Bytes\u0026#39;: image_bytes}, # Pass the image as bytes MaxLabels=10, # Limit to 10 labels returned MinConfidence=75 # Only get labels with at least 75% confidence ) # Return the recognition result as JSON return { \u0026#34;statusCode\u0026#34;: 200, \u0026#34;body\u0026#34;: json.dumps({ \u0026#34;labels\u0026#34;: response.get(\u0026#39;Labels\u0026#39;, []), \u0026#34;message\u0026#34;: \u0026#34;Image analyzed successfully\u0026#34; }), \u0026#34;headers\u0026#34;: { \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34;, \u0026#34;Access-Control-Allow-Origin\u0026#34;: \u0026#34;*\u0026#34; # Allow calls from frontend } } except Exception as e: # If there is an error, log it and return a 500 error code print(\u0026#34;Error:\u0026#34;, str(e)) return { \u0026#34;statusCode\u0026#34;: 500, \u0026#34;body\u0026#34;: json.dumps({\u0026#34;error\u0026#34;: str(e)}) } After entering the code in the Code Source section as above, you can save your changes by: Clicking the Deploy button or using the shortcut (Ctrl + Shift + U) Wait a few seconds, the system will save all your changes and return a successful save notification Result as shown in the images below: You have completed the step of configuring the Lambda Function for the Analyze Image feature by calling the AWS Rekognition\n"
},
{
	"uri": "//localhost:1313/4-apigateway/4.1-analyzeimage/",
	"title": "Configure API Analyze Image",
	"tags": [],
	"description": "",
	"content": "Configure API Gateway for the Analyze Image function 1. Search for and access the API Gateway service page\nIn the search bar, enter API Gateway The result will be displayed as shown below: On the main page of the API Gateway service on AWS, you can create a new API by clicking the Create an API button on the right, as shown below: 2. Configure API Gateway for the Analyze Image function\nOn the page to add a new API, you can see many types of APIs for different purposes such as: HTTP API, WebSocket API, REST API, etc. In this section, we will use HTTP API In the Choose an API type: section:\nSelect HTTP API Click the Build button The result is as shown below: Next, after performing the previous step, you will be taken to the API configuration page consisting of 4 steps: Configure API, Configure routes, Define Stages, Review and Create. Here, you will configure the API according to these 4 steps to Build an API Gateway In the Configure API: section:\nAPI name: enter a name for the API. For example: AnalyzeImage IP address type: select IPv4 In the Integration: section:\nHere is where you will connect one of the services to the API Select Add Integration Choose the Lambda service AWS Region: select your current Region. For example, in this lab: ap-southeast-1 Lambda function: select the function created in the previous section, here we choose AnalyzeImage Version: select 2.0 After configuring the above steps, click the Next button Next, you will be taken to Step 2: Configure routes On this page, you will configure the API to perform the image analysis function using the path and one of the API methods as shown below: In the Configure routes: section:\nMethod: select POST Resource path: you can freely set the API path. For example: /AnalyzeImage Integration target: select AnalyzeImage After configuring the above steps, click the Next button In Step 3: Define stages\nLeave the default values for Stages You can choose to Deploy the API manually or automatically whenever there are changes In this example, I will leave it as the default Auto-deploy After configuring the above steps, click the Next button In Step 4: Review and create\nOn this page, you will review all the configurations from the previous 3 steps If there are any mistakes, you can click the Edit button in each section After checking all the API configurations, click Create to create the API Wait a moment, the system will successfully create your API and return a success notification as shown below: 3. Configure CORS for the API to communicate with the Front-End and read JSON data\nOn the right side of the Navigation Panel, in the Develop section, select CORS as shown below: On the CORS page, you can see the configurable parts of CORS including: Access-Control-Allow-Origin, Access-Control-Allow-Headers, Access-Control-Allow-Methods, Access-Control-Expose-Headers, Access-Control-Max-Age, Access-Control-Allow-Credentials. In the Configure CORS: section:\nClick the button in the top right corner: Configure Access-Control-Allow-Origin: enter (*) to allow all domains to access, or you can specify the exact domain you want the API to communicate with Access-Control-Allow-Headers: enter content-type to allow reading input in JSON format Access-Control-Allow-Methods: select POST to match the routes configured earlier Leave the remaining CORS settings as default After configuring all the above steps, click the Save button Note, this is a required configuration step. If you skip this step, the API will not be able to communicate with the Front-End.\nYou have completed the API configuration for the image analysis function using AWS Rekognition\n"
},
{
	"uri": "//localhost:1313/",
	"title": "Intelligent Image Recognition",
	"tags": [],
	"description": "",
	"content": "Intelligent Image Recognition with Amazon Rekognition and Serverless Stack Overall In this lab, you will learn the basic concepts and practice using Amazon Rekognition – a powerful AI image recognition service, and how to implement a Serverless Stack solution. You will practice creating automated pipelines to analyze and recognize images using Amazon Rekognition, while integrating Serverless services such as AWS Lambda, S3, and API Gateway to build an intelligent image processing system.\nContent Introduction Preparation Configure Lambda Function Configure API Gateway Experiment Results View Activity Logs with CloudWatch Update Policy for S3 Bucket (Optional) Reference Video Demo Clean Up Resources "
},
{
	"uri": "//localhost:1313/1-introduce/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Amazon Rekognition is a powerful AI service from AWS that provides the ability to recognize and analyze images and videos. Amazon Rekognition helps you identify objects, faces, text, and scenes in images without the need to build complex deep learning models. Below is the deployment model of the lab:\nThe steps of operation of the model:\nStep 1: The user uploads an image from the web interface to perform image recognition. Step 2: The frontend sends the image via HTTP POST to API Gateway to initiate processing. Step 3: API Gateway triggers a Lambda function to handle the image analysis request. Step 4: The Lambda function logs activities (events, errors, recognition details) to CloudWatch for monitoring and tracking. Step 5: The Lambda function sends the image to the Rekognition service to analyze its content and extract information. Step 6: Rekognition returns the analysis results (labels, objects, confidence scores) in JSON format. Step 7: The Lambda function generates a JSON file containing the results and optionally processes the input image. Step 8: Both the original image and the JSON file are stored in an S3 bucket for long-term storage or sharing. Step 9: The Lambda function is granted permissions via an IAM Role to invoke Rekognition, write logs to CloudWatch, and upload data to S3. By using Amazon Rekognition, you will gain the following advantages:\nEasily identify objects and faces in images without needing to build your own AI model. Support for text analysis in images, helping to recognize information and text on photos. Can be configured and integrated with AWS Serverless services such as Lambda, S3, and API Gateway, enabling quick deployment and cost savings. Automates image and video analysis processes without the need for expensive hardware or infrastructure management. Provides easy-to-use APIs for image and video recognition, making it simple for developers to integrate into applications. Manages access permissions and security through AWS IAM to ensure compliance with company policies. Logs actions and analysis results, making it easy for users to track and verify the effectiveness of AI models. With these benefits, you can use Amazon Rekognition and Serverless Stack to build intelligent image recognition applications, saving time and costs in system deployment and maintenance.\n"
},
{
	"uri": "//localhost:1313/4-apigateway/4.2-uploadimage/",
	"title": "Configure API Upload Image",
	"tags": [],
	"description": "",
	"content": "Configure API Gateway for the function to upload images and analysis results to S3 Bucket 1. Return to the APIs page to view the list of existing APIs\nAfter configuring CORS for the API in the previous section, you can return to the APIs list page by: On the left Navigation Panel, select APIs On the APIs list page, you can see the AnalyzeImage API created in the previous step as shown below: In the top right corner, click Create API 2. Configure API Gateway for the Upload Image function\nOn the page to add a new API, you can see many types of APIs for different purposes such as: HTTP API, WebSocket API, REST API, etc. In this section, we will use HTTP API In the Choose an API type: section:\nSelect HTTP API Click the Build button The result is as shown below: Next, after performing the previous step, you will be taken to the API configuration page consisting of 4 steps: Configure API, Configure routes, Define Stages, Review and Create. Here, you will configure the API according to these 4 steps to Build an API Gateway In the Configure API: section:\nAPI name: enter a name for the API. For example: UploadImage IP address type: select IPv4 In the Integration: section:\nHere is where you will connect one of the services to the API Select Add Integration Choose the Lambda service AWS Region: select your current Region. For example, in this lab: ap-southeast-1 Lambda function: select the function created in the previous section, here we choose UploadImage Version: select 2.0 After configuring the above steps, click the Next button Next, you will be taken to Step 2: Configure routes On this page, you will configure the API to perform the upload image function using the path and one of the API methods as shown below: In the Configure routes: section:\nMethod: select POST Resource path: you can freely set the API path. For example: /UploadImage Integration target: select UploadImage After configuring the above steps, click the Next button In Step 3: Define stages\nLeave the default values for Stages You can choose to Deploy the API manually or automatically whenever there are changes In this example, I will leave it as the default Auto-deploy After configuring the above steps, click the Next button In Step 4: Review and create\nOn this page, you will review all the configurations from the previous 3 steps If there are any mistakes, you can click the Edit button in each section After checking all the API configurations, click Create to create the API Wait a moment, the system will successfully create your API and return a success notification as shown below: 3. Configure CORS for the API to communicate with the Front-End and read JSON data\nOn the right side of the Navigation Panel, in the Develop section, select CORS as shown below: On the CORS page, you can see the configurable parts of CORS including: Access-Control-Allow-Origin, Access-Control-Allow-Headers, Access-Control-Allow-Methods, Access-Control-Expose-Headers, Access-Control-Max-Age, Access-Control-Allow-Credentials. Click the button in the top right corner: Configure In the Configure CORS: section:\nAccess-Control-Allow-Origin: enter (*) to allow all domains to access, or you can specify the exact domain you want the API to communicate with Access-Control-Allow-Headers: enter content-type to allow reading input in JSON format Access-Control-Allow-Methods: select POST to match the routes configured earlier Leave the remaining CORS settings as default After configuring all the above steps, click the Save button Note, this is a required configuration step. If you skip this step, the API will not be able to communicate with the Front-End.\nYou have completed the API configuration for uploading images and analysis results to S3 Bucket\n"
},
{
	"uri": "//localhost:1313/3-lambdafunction/3.2-uploadfunction/",
	"title": "Configure Upload Function",
	"tags": [],
	"description": "",
	"content": "Configure the Upload Function to upload images and analysis results 1. Go to the list page containing Lambda functions\nIn the previous section, after configuring the Analyze Function, you can quickly return to the list of existing Lambda Functions as follows: Look at the top left corner, you will see the Functions section Result as shown below: On the page displaying all existing Functions, you can see the Analyze Function that you configured earlier Next, click the Create function button on the right corner to create a new function as shown below: 2. Configure the Upload Function on the Create function page\nOn the creation page, to configure the function you are about to create, You need to enter information and select the most suitable configurations for the lab. Please follow these steps: In the first section, there are 3 options to create a template for the Lambda Function: Author from scratch, Use a blueprint, Container image\nSelect Author from scratch, this will create a simple code structure with a sample content that prints Hello World In the Basic information section:\nFunction name: enter a name for the function. For example: UploadImage (or any name you prefer) Runtime: select Python 3.11 Architecture: select x86_64 In the Change default execution role section:\nExecution role: select Use an existing role, this allows you to choose a Role that was created earlier and is suitable for the Lambda Function Existing role: select LambdaAnalyzeRole, this is the Role created in the previous section After configuring, click the Create function button to create the Lambda function Result as shown below: Wait a few seconds for the system to create the Lambda function you have configured After creation, the system will return a successful creation notification for your Lambda function as shown below: Here is where you can write code in Python as configured earlier: 3. Configure the Upload Function code in the Code Source section\nHere you will enter the code so that the upload image and analysis result function can work Enter the code with the following structure: import json import boto3 import base64 import uuid import os # Initialize S3 client s3 = boto3.client(\u0026#39;s3\u0026#39;) # Get bucket name from environment variable (replace with your bucket name) BUCKET = os.environ.get(\u0026#34;BUCKET_NAME\u0026#34;, \u0026#34;your-bucket-name\u0026#34;) def lambda_handler(event, context): try: # Parse body content from HTTP request (JSON format) body = json.loads(event[\u0026#34;body\u0026#34;]) # Get image data (base64) and analysis result sent from frontend image_base64 = body.get(\u0026#34;image\u0026#34;) result_data = body.get(\u0026#34;result\u0026#34;) # Check if image or result is missing, return error if not image_base64 or not result_data: return { \u0026#34;statusCode\u0026#34;: 400, \u0026#34;body\u0026#34;: json.dumps({\u0026#34;error\u0026#34;: \u0026#34;Missing image or result\u0026#34;}) } # Decode base64 image to bytes image_bytes = base64.b64decode(image_base64) # Generate random image filename using UUID filename = f\u0026#34;image-{uuid.uuid4()}.jpg\u0026#34; # Upload original image to \u0026#39;images/\u0026#39; folder in S3 bucket s3.put_object( Bucket=BUCKET, Key=f\u0026#34;images/{filename}\u0026#34;, Body=image_bytes, ContentType=\u0026#34;image/jpeg\u0026#34; ) # Generate corresponding JSON filename and upload analysis result to \u0026#39;results/\u0026#39; folder s3.put_object( Bucket=BUCKET, Key=f\u0026#34;results/{filename.replace(\u0026#39;.jpg\u0026#39;, \u0026#39;.json\u0026#39;)}\u0026#34;, Body=json.dumps(result_data), ContentType=\u0026#34;application/json\u0026#34; ) # Return success result to frontend, including image and JSON file links return { \u0026#34;statusCode\u0026#34;: 200, \u0026#34;body\u0026#34;: json.dumps({ \u0026#34;message\u0026#34;: \u0026#34;Upload successful\u0026#34;, \u0026#34;imageUrl\u0026#34;: f\u0026#34;https://{BUCKET}.s3.amazonaws.com/images/{filename}\u0026#34;, \u0026#34;resultUrl\u0026#34;: f\u0026#34;https://{BUCKET}.s3.amazonaws.com/results/{filename.replace(\u0026#39;.jpg\u0026#39;, \u0026#39;.json\u0026#39;)}\u0026#34; }), \u0026#34;headers\u0026#34;: { \u0026#34;Access-Control-Allow-Origin\u0026#34;: \u0026#34;*\u0026#34;, # Allow access from any domain \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34; } } except Exception as e: # Return 500 error if exception occurs and allow CORS return { \u0026#34;statusCode\u0026#34;: 500, \u0026#34;body\u0026#34;: json.dumps({\u0026#34;error\u0026#34;: str(e)}), \u0026#34;headers\u0026#34;: {\u0026#34;Access-Control-Allow-Origin\u0026#34;: \u0026#34;*\u0026#34;} } After entering the code in the Code Source section as above, you can save your changes by: Clicking the Deploy button or using the shortcut (Ctrl + Shift + U) Wait a few seconds, the system will save all your changes and return a successful save notification Note, please replace your bucket name, do not duplicate the bucket name\nResult as shown in the images below: You have completed the step of configuring the Lambda Function for uploading images and analysis results\n"
},
{
	"uri": "//localhost:1313/2-prerequiste/2.2-creates3bucket/",
	"title": "Create an S3 Bucket for Storage",
	"tags": [],
	"description": "",
	"content": "Initialize an S3 Bucket for storing images and analysis results 1. Access the Console and find the Amazon S3 service\nGo to the AWS Management Console Then, log in to your account as shown below: After clicking the page, the login screen with required fields will appear as shown below: Note, this is a mandatory requirement to proceed to the next steps. If you do not have an account, please register for one.\nReference link for account creation: Create an account\nAfter successfully logging in, you will be redirected to the main page of the AWS Management Console as shown below:\nIn the search bar, type S3 Select the S3 service Result as shown below: You can star the services you use frequently during the process, making it more convenient for quick access.\nOn the main interface of the S3 service, click the Create Bucket button as shown below: 2. Configure the S3 Bucket\nAfter clicking Create Bucket, you will be taken to the bucket creation section as shown below: In the General configuration section:\nAWS Region: Asia Pacific (Singapore) ap-southeast-1 (or any region you want to use) Bucket type: select General purpose Bucket name: enter rekognition-image-upload-0912 In the Object Ownership section:\nSelect ACLs disable (recommended) Note, your Bucket Name must be unique and not duplicate any other buckets.\nIn the Block Public Access setting for this bucket section:\nUncheck Block all public access Uncheck Block public access to buckets and objects granted through new access control lists (ACLs) Uncheck Block public access to buckets and objects granted through any access control lists (ACLs) Uncheck Block public access to buckets and objects granted through new public bucket or access point policies Uncheck Block public and cross-account access to buckets and objects through any public bucket or access point policies Check I acknowledge that the current settings might result in this bucket and the objects within becoming public. In the Bucket Versioning section:\nBucket Versioning: select Disable In the Default Encryption section:\nEncryption type: select Server-side encryption with Amazon S3 managed keys (SSE-S3) Bucket key: select Enable After completing the above steps, scroll to the bottom of the page and click Create Bucket as shown below: Wait a few seconds, you will be redirected to the bucket list page and a successful bucket creation notification will appear as shown below: You have completed the step of creating an S3 Bucket to store images and\n"
},
{
	"uri": "//localhost:1313/2-prerequiste/",
	"title": "Prerequiste",
	"tags": [],
	"description": "",
	"content": "Overview Before starting to implement the intelligent image recognition AI system, you need to prepare some basic components in the AWS environment to ensure the smooth process of analysis and storage. Specifically, you will create an S3 Bucket to store the original images uploaded by the user, as well as the analysis results in JSON format. Next, you need to configure an IAM Role with appropriate permissions such as AmazonS3FullAccess, AmazonRekognitionFullAccess, CloudWatchLogsFullAccess\u0026hellip; so that the Lambda function can call the Rekognition service, log data to CloudWatch, and write data to S3.\nContent Clone and Setup Front-End Create an S3 Bucket for storage Create IAM Role and Attach Policy "
},
{
	"uri": "//localhost:1313/3-lambdafunction/",
	"title": "Configure Lambda Function",
	"tags": [],
	"description": "",
	"content": "Overview In this section, you will configure the AWS Lambda Function – a core component in the intelligent image recognition AI system. Lambda acts as an intermediary processor: it receives images from users via API Gateway, sends the images to Amazon Rekognition for content analysis, processes the results, and stores the analysis information as JSON in S3. Additionally, Lambda logs the entire operation process to CloudWatch for monitoring and troubleshooting purposes. Properly configuring the Lambda function is an important step to ensure the system operates accurately, securely, and can scale flexibly following the Serverless model.\nContents Configure Analyze Function Configure Upload Function "
},
{
	"uri": "//localhost:1313/2-prerequiste/2.3-createiamrole/",
	"title": "Create IAM Role and Attach Policy",
	"tags": [],
	"description": "",
	"content": "Create a new IAM Role and Attach Policy to the Role 1. Search for and access the IAM service to create a Role\nIn the search bar, enter IAM After searching, click on the IAM service as shown below: On the IAM service page, in the left Navigation Panel Select Roles as shown below: On the Roles page, you can see a list of many popular and frequently used AWS Roles On the right side, click the Create Role button as follows: 2. Create a new Role and configure details\nOn the Create Role page, you can see that creating a Role involves 3 main steps as shown below: In the Select Trusted entity section:\nTrusted entity type: Select AWS Service In the Use Case section:\nService or use case: select Lambda Then click the Next button On the Step 2 Add permissions to Role page, you can see more than 1000+ Permission Policies as shown below: However, you only need to find a few Policies suitable for the Lab Here, we will search for and select 3 Policies to use: AmazonS3FullAccess, AmazonRekognitionFullAccess, CloudWatchLogsFullAccess. After selecting, click the Next button Results as shown in the images below: On the Step 3: Name, review, and create page, you will review all configurations from the previous two steps In the Role details section:\nRole name: set a name for the Role, e.g., LambdaAnalyzeRole Description: you can leave it as default or add notes as you wish In the Step 2: Add Permission section, you can review the Policies you added in detail After checking all the information, click Create Role to proceed Wait a few seconds, after creation the system will redirect you to the main Roles page and display a success notification as shown below: You have completed the necessary preparation steps to proceed to the next step.\n"
},
{
	"uri": "//localhost:1313/4-apigateway/",
	"title": "Configure API Gateway",
	"tags": [],
	"description": "",
	"content": "Overview In this section, you will configure Amazon API Gateway – the component that acts as a bridge between the user interface (frontend) and the serverless backend (AWS Lambda). API Gateway will receive HTTP requests from the web application (such as when users upload images), then forward these requests to the Lambda function for processing. Properly configuring API Gateway ensures the system can communicate reliably, securely, and scale flexibly. At the same time, you will also configure CORS (Cross-Origin Resource Sharing) to allow the web application to access API resources correctly, especially when the frontend and backend are deployed on different domains. This is an important step to complete the communication process between the React frontend and the backend AWS services.\nContents Configure API Analyze Image Configure API Upload Image "
},
{
	"uri": "//localhost:1313/5-results/",
	"title": "Experiment Results",
	"tags": [],
	"description": "",
	"content": "Check and execute the application\u0026rsquo;s results for both functions In this section, you will deploy the application with all the components configured, including API Gateway, Lambda function, and S3 Bucket. You will connect the frontend user interface with the serverless backend to handle image analysis requests. This process starts when the user uploads an image through the web interface, and the application sends the image to API Gateway, where the request is forwarded to the Lambda function to perform image recognition with Amazon Rekognition. After recognition, the result will be stored in the S3 Bucket and returned to the user as a link for easy access.\n1. Save the Endpoint and Routes links of the APIs\nIn the previous section, after creating and configuring 2 APIs: AnalyzeImage and UploadImage In this section, you need to save the 2 Endpoint and Routes links On the left Navigation Panel, select the section as shown below: On this page, all detailed information of this API will be displayed In the API details section, at the top right, there is the Default Endpoint Here, the Invoke URL of the API and its status will be displayed Copy this Endpoint link as shown below: Note, this is a random API Endpoint, each API will have a different link, so please replace it with your own API link\n2. Replace the Endpoint and Routes links of the AnalyzeImage API\nGo back to the Front-End Project in section 1 Find the configuration folder and file at: src/App.jsx Next, find the handleAnalyzeImage function In this function, replace the API link you just copied in the previous step Result as shown below: Next, find the routes of the API configured earlier And copy the routes of the POST method with the path /AnalyzeImage Result as shown below: Next, append it to the end of the API Endpoint in the code and save as follows: 3. Replace the Endpoint and Routes links of the UploadImage API\nGo back to the Front-End Project in section 1 Find the configuration folder and file at: src/App.jsx Next, find the UploadImage API on the system page Then copy the EndPoint of the UploadImage API Result as shown below: Next, find the handleUploadToS3 function\nIn this function, replace the API link you just copied in the previous step\nResult as shown below:\nNext, find the routes of the API configured earlier And copy the routes of the POST method with the path /UploadImage Result as shown below: Next, append it to the end of the API Endpoint in the code and save as follows: 4. Check the results\nIn the Project, under the terminal window Enter the following command to run the Web page: npm run dev Wait a few seconds, the code will run and display the link to access the website You can hover over the link in the Terminal and press: Ctrl + Left Click Or access http://localhost:5173/ to open the website On the website, there will be a section for you to drop an image or select an image from your computer as follows: After uploading any image from your computer You will see that the website can perform 2 functions: AnalyzeImage, Upload To S3 Follow the steps numbered in the images as follows: Analyze Image function:\nAfter successfully uploading the image Click the Analyze Image button to perform the function Wait a moment, then the website will display the analysis result in the Component Result Result as shown below: You can view the detailed JSON Script that contains the image analysis result returned by AWS Rekognition with information such as Label, Name, Confidence, etc. The result will include up to 10 labels with confidence above 75% Labels: label Name: Name of the object Confidence: Confidence level Categories: Category Detailed result as shown below: Upload Image function (Upload image and analysis result to S3):\nAfter performing the image analysis function Next, you will upload the image to the S3 Bucket by clicking the Upload To S3 button Wait a moment, when the image and result have been successfully uploaded to the S3 Bucket, the system will return a success notification as shown below: Check the S3 Bucket to see if the image and analysis result have actually been uploaded as follows: Access the S3 Bucket and click on your Bucket name Result as shown in the images below: You can see that the S3 Bucket will automatically create 2 folders: images and results After checking, you will see that there is 1 image and 1 JSON file in the corresponding folder as follows: Congratulations, you have completed the experiment and can now refer to one of many ways to maximize the power of AWS services deployed in this lab.\n"
},
{
	"uri": "//localhost:1313/6-cloudwatch/",
	"title": "View Activity Logs with CloudWatch",
	"tags": [],
	"description": "",
	"content": "Check Website Activity Logs with CloudWatch 1. Search for and access the CloudWatch service page\nIn the search bar, enter: CloudWatch The result will be displayed as shown below: On the main page of the CloudWatch service On the left Navigation Panel, select Log groups The result will be displayed as shown below: 2. Check and view activity logs\nOn the main Log groups page You can see that there are 2 Log groups automatically created after we performed the Analyze Image and Upload Image functions in the previous section This is where we can check how the functions operate Select the Log group for the Analyze Image function On the Log group details page for the Analyze Image function You can see other detailed information Especially Log Streams, these are the main activity streams each time you perform the function; each execution will add a Log Stream to record the detailed activity of that execution Here are the details of the Log Streams activity: Let\u0026rsquo;s try an example where the Analyze Image function encounters an error and check the Log Streams result First, go to the Lambda Function for the Analyze Image function Then proceed to edit any line of code as follows: Explanation: We will edit the line of code as shown above so that the lambda function cannot call the AWS Rekognition service client. The system will then report an error on the Front-End because it cannot perform the image analysis function and will record the error Log Streams as shown in the following images: Through this section, you can understand how Log groups work in CloudWatch. This service will help you conveniently monitor your application\u0026rsquo;s activities and easily display all error information, making\n"
},
{
	"uri": "//localhost:1313/7-s3policy/",
	"title": "Update Policy for S3 Bucket (Optional)",
	"tags": [],
	"description": "",
	"content": "Update the Policy configuration for the S3 Bucket to view image information and analysis results Note, this is the configuration section for the S3 Bucket Policy. To be able to directly view images and image analysis results via a public URL, you can refer to this section.\n1. Access the S3 Bucket Policy details page\nIn section 5, we were able to perform the image analysis function and upload images to the S3 Bucket However, viewing images and results will be denied because the S3 bucket policy has not been set up yet First, click on the image as shown below: Then, the system will redirect the user to the detailed information page of that Object On the detailed information page of the Object (image), look to the right corner and you will see an Object URL section This is the URL of the Object, you can click or copy it to a new browser tab to view: The result will be displayed as shown in the images below: After accessing the Object URL link, you may see the system report Access Denied and the image cannot be displayed 2. Configure the S3 Bucket Policy to view images and analysis results\nGo back to the Bucket list page, click on the Bucket name Here, switch to the Permission tab as shown below: On the information page of the Permission tab Scroll down a bit You will see the Bucket policy section, look to the right and click the Edit button This allows you to edit the policy of the Bucket After switching to the Edit Bucket Policy section, you will see the part where we will edit by adding a JSON Script as shown below: Here, you will configure the Bucket policy with the following JSON code: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, // Policy version, according to AWS IAM standard \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AllowPublicReadAccessToImagesAndResultFolders\u0026#34;, // Identifier for the policy statement (can be changed for easier identification) \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, // Specifies the \u0026#34;Allow\u0026#34; action for the actions described below \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, // Specifies that all users (Public Access) can perform this action \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, // Grants permission to perform the \u0026#34;s3:GetObject\u0026#34; action, i.e., allows users to read (GET) objects from S3 \u0026#34;Resource\u0026#34;: [ // Grants permission for the specific resources below \u0026#34;arn:aws:s3:::your-bucket-name/images/*\u0026#34;, // Allows access to objects in the \u0026#34;images\u0026#34; folder of the bucket \u0026#34;arn:aws:s3:::your-bucket-name/results/*\u0026#34; // Allows access to objects in the \u0026#34;results\u0026#34; folder of the bucket ] } ] } Note, please replace with your own S3 Bucket name\nAfter configuring as above, you will get the result as shown below Save the changes by clicking the Save changes button Wait a few seconds, the system will process and return a success notification along with the updated Bucket policy displayed on the website as follows: Go back to the detailed information page of the Object Access the Object URL link The result will be displayed as shown in the images below: Here, you can now view the image directly via the public object URL as shown below: Similarly, in the Edit Policy section of the Bucket, we have also configured the /result folder so that you can view the image analysis results as shown below: Through this section, you can refer to how to quickly and directly view images\n"
},
{
	"uri": "//localhost:1313/8-demo/",
	"title": "Reference Video Demo",
	"tags": [],
	"description": "",
	"content": "Reference Video Demo for the entire lab In the Reference Video Demo section, you will experience a visual walkthrough of the entire process of deploying an intelligent image recognition system with Amazon Rekognition and the Serverless Stack. The video will guide you step-by-step, from configuring AWS services such as Lambda, API Gateway, and S3 to image processing: uploading images to the system, analyzing images via Rekognition, and storing analysis results in S3. Through the video, you will clearly see how these components connect and interact in practice, helping you easily visualize and grasp the process, while also providing tips and techniques to apply to your own project.\nReference Demo Link: Here "
},
{
	"uri": "//localhost:1313/9-cleanup/",
	"title": "Clean Up Resources",
	"tags": [],
	"description": "",
	"content": "Clean up service resources after use 1. Clean up IAM service\nIn the search bar, enter IAM On the IAM service page, on the left Navigation Panel, select Role On the Roles page, search for LambdaAnalyzeRole, check LambdaAnalyzeRole Click the Delete button, enter the Role name: LambdaAnalyzeRole 2. Clean up S3 service\nIn the search bar, enter S3 On the General purpose buckets page, select the bucket you want to delete Click the Empty button to delete all Objects in the bucket before deleting the Bucket Enter permanently delete and click Empty to delete the Objects Go back, select the bucket you want to delete, click Delete Enter your bucket name, click Delete Bucket 3. Clean up Lambda service\nIn the search bar, enter Lambda Select the functions you want to delete, click the Action button, choose Delete Enter confirm and click Delete 4. Clean up CloudWatch service\nIn the search bar, enter CloudWatch On the main CloudWatch page, on the left Navigation Panel select Log groups Select the Log group you want to delete, click Action, choose Delete log group(s) In the popup window, select Delete 5. Clean up API Gateway service\nIn the search bar, enter API Gateway Select the API you want to delete, click Delete on the right Enter confirm, click Delete Repeat for the remaining APIs Congratulations, you have completed the entire lab. This section will help you save costs by cleaning up unused AWS services. Thank you for taking the time to read and "
},
{
	"uri": "//localhost:1313/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]